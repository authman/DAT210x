{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module5- Lab6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot') # Look Pretty\n",
    "\n",
    "\n",
    "# Leave this alone until indicated:\n",
    "Test_PCA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Convenience Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is for your visualization convenience only. You aren't expected to know how to put this together yourself, although you should be able to follow the code by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot2DBoundary(DTrain, LTrain, DTest, LTest):\n",
    "    # The dots are training samples (img not drawn), and the pics are testing samples (images drawn)\n",
    "    # Play around with the K values. This is very controlled dataset so it should be able to get perfect classification on testing entries\n",
    "    # Play with the K for isomap, play with the K for neighbors. \n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('Transformed Boundary, Image Space -> 2D')\n",
    "\n",
    "    padding = 0.1   # Zoom out\n",
    "    resolution = 1  # Don't get too detailed; smaller values (finer rez) will take longer to compute\n",
    "    colors = ['blue','green','orange','red']\n",
    "\n",
    "\n",
    "    # ------\n",
    "\n",
    "    # Calculate the boundaries of the mesh grid. The mesh grid is\n",
    "    # a standard grid (think graph paper), where each point will be\n",
    "    # sent to the classifier (KNeighbors) to predict what class it\n",
    "    # belongs to. This is why KNeighbors has to be trained against\n",
    "    # 2D data, so we can produce this countour. Once we have the \n",
    "    # label for each point on the grid, we can color it appropriately\n",
    "    # and plot it.\n",
    "    x_min, x_max = DTrain[:, 0].min(), DTrain[:, 0].max()\n",
    "    y_min, y_max = DTrain[:, 1].min(), DTrain[:, 1].max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_max += y_range * padding\n",
    "\n",
    "    # Using the boundaries, actually make the 2D Grid Matrix:\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                         np.arange(y_min, y_max, resolution))\n",
    "\n",
    "    # What class does the classifier say about each spot on the chart?\n",
    "    # The values stored in the matrix are the predictions of the model\n",
    "    # at said location:\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the mesh grid as a filled contour plot:\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.terrain, z=-100)\n",
    "\n",
    "\n",
    "    # ------\n",
    "\n",
    "    # When plotting the testing images, used to validate if the algorithm\n",
    "    # is functioning correctly, size them as 5% of the overall chart size\n",
    "    x_size = x_range * 0.05\n",
    "    y_size = y_range * 0.05\n",
    "\n",
    "    # First, plot the images in your TEST dataset\n",
    "    img_num = 0\n",
    "    for index in LTest.index:\n",
    "        # DTest is a regular NDArray, so you'll iterate over that 1 at a time.\n",
    "        x0, y0 = DTest[img_num,0]-x_size/2., DTest[img_num,1]-y_size/2.\n",
    "        x1, y1 = DTest[img_num,0]+x_size/2., DTest[img_num,1]+y_size/2.\n",
    "\n",
    "        # DTest = our images isomap-transformed into 2D. But we still want\n",
    "        # to plot the original image, so we look to the original, untouched\n",
    "        # dataset (at index) to get the pixels:\n",
    "        img = df.iloc[index,:].reshape(num_pixels, num_pixels)\n",
    "        ax.imshow(img,\n",
    "                  aspect='auto',\n",
    "                  cmap=plt.cm.gray,\n",
    "                  interpolation='nearest',\n",
    "                  zorder=100000,\n",
    "                  extent=(x0, x1, y0, y1),\n",
    "                  alpha=0.8)\n",
    "        img_num += 1\n",
    "\n",
    "\n",
    "    # Plot your TRAINING points as well... as points rather than as images\n",
    "    for label in range(len(np.unique(LTrain))):\n",
    "        indices = np.where(LTrain == label)\n",
    "        ax.scatter(DTrain[indices, 0], DTrain[indices, 1], c=colors[label], alpha=0.8, marker='o')\n",
    "\n",
    "    # Plot\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use the same code from Module4/assignment4.ipynb to load up the `face_data.mat` file into a dataframe called `df`. Be sure to calculate the `num_pixels` value, and to rotate the images to being right-side-up instead of sideways. This was demonstrated in the [Lab Assignment 4](https://github.com/authman/DAT210x/blob/master/Module4/assignment4.ipynb) code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pixels', 64, (698, 4096))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferryto\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.056710</td>\n",
       "      <td>0.192279</td>\n",
       "      <td>0.380607</td>\n",
       "      <td>0.504733</td>\n",
       "      <td>0.514920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.110754</td>\n",
       "      <td>0.384988</td>\n",
       "      <td>0.510034</td>\n",
       "      <td>0.608609</td>\n",
       "      <td>0.743229</td>\n",
       "      <td>0.735126</td>\n",
       "      <td>0.664675</td>\n",
       "      <td>0.774494</td>\n",
       "      <td>0.792233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.016176  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.016176  0.000000  0.000000  0.000000  0.007062  0.056710  0.192279   \n",
       "2  0.016176  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.016176  0.110754  0.384988  0.510034  0.608609  0.743229  0.735126   \n",
       "4  0.016176  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       7         8         9     ...       4086  4087  4088  4089  4090  4091  \\\n",
       "0  0.000000  0.000000  0.000000  ...   0.000781   0.0   0.0   0.0   0.0   0.0   \n",
       "1  0.380607  0.504733  0.514920  ...   0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "2  0.000000  0.000000  0.000000  ...   0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "3  0.664675  0.774494  0.792233  ...   0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "4  0.000000  0.000000  0.000000  ...   0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   4092  4093  4094  4095  \n",
       "0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = scipy.io.loadmat('Datasets/face_data.mat')\n",
    "df = pd.DataFrame(mat['images']).T\n",
    "num_images, num_pixels = df.shape\n",
    "num_pixels = int(math.sqrt(num_pixels)) #pixels per row\n",
    "\n",
    "print ('pixels', num_pixels, df.shape)\n",
    "# Rotate the pictures, so we don't have to crane our necks:\n",
    "for i in range(num_images):\n",
    "    df.loc[i,:] = df.loc[i,:].reshape(num_pixels, num_pixels).T.reshape(-1)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up your face_labels dataset. It only has a single column, and you're only interested in that single column. You will have to slice the  column out so that you have access to it as a \"Series\" rather than as a \"Dataframe\". This was discussed in the the \"Slicin'\" lecture of the  \"Manipulating Data\" reading on the course website. Use an appropriate indexer to take care of that. Be sure to print out the labels and compare what you see to the raw `face_labels.csv` so you know you loaded it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(698, 1)\n",
      "     0\n",
      "0    0\n",
      "1    2\n",
      "2    0\n",
      "3    2\n",
      "4    0\n",
      "5    2\n",
      "6    2\n",
      "7    2\n",
      "8    2\n",
      "9    0\n",
      "10   2\n",
      "11   0\n",
      "12   3\n",
      "13   0\n",
      "14   0\n",
      "15   0\n",
      "16   1\n",
      "17   3\n",
      "18   3\n",
      "19   1\n",
      "20   2\n",
      "21   0\n",
      "22   1\n",
      "23   3\n",
      "24   0\n",
      "25   1\n",
      "26   0\n",
      "27   1\n",
      "28   2\n",
      "29   2\n",
      "..  ..\n",
      "668  1\n",
      "669  2\n",
      "670  0\n",
      "671  2\n",
      "672  2\n",
      "673  3\n",
      "674  2\n",
      "675  2\n",
      "676  2\n",
      "677  0\n",
      "678  1\n",
      "679  0\n",
      "680  1\n",
      "681  1\n",
      "682  1\n",
      "683  3\n",
      "684  3\n",
      "685  2\n",
      "686  3\n",
      "687  1\n",
      "688  0\n",
      "689  3\n",
      "690  1\n",
      "691  3\n",
      "692  2\n",
      "693  3\n",
      "694  0\n",
      "695  2\n",
      "696  2\n",
      "697  1\n",
      "\n",
      "[698 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('Datasets/face_labels.csv', header=None)\n",
    "print labels.shape\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, label_train, data_test, label_test = train_test_split(df,labels,test_size=0.15,random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do `train_test_split`. Use the same code as on the EdX platform in the reading material, but set the random_state=7 for reproducibility, and the test_size to 0.15 (150%). Your labels are actually passed in as a series (instead of as an NDArray) so that you can access their underlying indices later on. This is necessary so you can find your samples in the original dataframe. The convenience methods we've written for you that handle drawing expect this, so that they can plot your testing data as images rather than as points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Test_PCA:\n",
    "    # INFO: PCA is used *before* KNeighbors to simplify your high dimensionality\n",
    "    # image samples down to just 2 principal components! A lot of information\n",
    "    # (variance) is lost during the process, as I'm sure you can imagine. But\n",
    "    # you have to drop the dimension down to two, otherwise you wouldn't be able\n",
    "    # to visualize a 2D decision surface / boundary. In the wild, you'd probably\n",
    "    # leave in a lot more dimensions, which is better for higher accuracy, but\n",
    "    # worse for visualizing the decision boundary;\n",
    "    #\n",
    "    # Your model should only be trained (fit) against the training data (data_train)\n",
    "    # Once you've done this, you need use the model to transform both data_train\n",
    "    # and data_test from their original high-D image feature space, down to 2D\n",
    "\n",
    "\n",
    "    # TODO: Implement PCA here. ONLY train against your training data, but\n",
    "    # transform both your training + test data, storing the results back into\n",
    "    # data_train, and data_test.\n",
    "    \n",
    "    # .. your code here ..\n",
    "\n",
    "else:\n",
    "    # INFO: Isomap is used *before* KNeighbors to simplify your high dimensionality\n",
    "    # image samples down to just 2 components! A lot of information has been is\n",
    "    # lost during the process, as I'm sure you can imagine. But if you have\n",
    "    # non-linear data that can be represented on a 2D manifold, you probably will\n",
    "    # be left with a far superior dataset to use for classification. Plus by\n",
    "    # having the images in 2D space, you can plot them as well as visualize a 2D\n",
    "    # decision surface / boundary. In the wild, you'd probably leave in a lot more\n",
    "    # dimensions, which is better for higher accuracy, but worse for visualizing the\n",
    "    # decision boundary;\n",
    "    \n",
    "    # Your model should only be trained (fit) against the training data (data_train)\n",
    "    # Once you've done this, you need use the model to transform both data_train\n",
    "    # and data_test from their original high-D image feature space, down to 2D\n",
    "\n",
    "    \n",
    "    # TODO: Implement Isomap here. ONLY train against your training data, but\n",
    "    # transform both your training + test data, storing the results back into\n",
    "    # data_train, and data_test.\n",
    "    \n",
    "    # .. your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `KNeighborsClassifier` here. You can use any K value from 1 through 20, so play around with it and attempt to get good accuracy. Fit the classifier against your training data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and display the accuracy of the testing set (data_test and label_test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's chart the combined decision boundary, the training data as 2D plots, and the testing data as small images so we can visually validate performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot2DBoundary(data_train, label_train, data_test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After submitting your answers, experiment with using using PCA instead of ISOMap. Are the results what you expected? Also try tinkering around with the test/train split percentage from 10-20%. Notice anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. your code changes above .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
