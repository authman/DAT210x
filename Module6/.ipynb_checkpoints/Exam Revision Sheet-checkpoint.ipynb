{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-784ef74e29f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#preprocessor = preprocessing.MaxAbsScaler().fit(X_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#preprocessor = preprocessing.MinMaxScaler().fit(X_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# If this line throws an error, use plt.style.use('ggplot') instead\n",
    "#mpl.style.use('ggplot') # Look Pretty\n",
    "#fig = plt.figure()\n",
    "#ax.scatter(df.area, df.perimeter, df.asymmetry ,c='r', marker='.')\n",
    "#ax.plot(X_test, model.predict(X_test), color='orange', linewidth=1, alpha=0.7)\n",
    "#df.plot.hist(alpha=0.75)\n",
    "#plt.show()\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#ax = Axes3D(fig)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "from plyfile import PlyData, PlyElement\n",
    "#PlyData.read('Datasets/stanford_armadillo.ply')\n",
    "\n",
    "from pandas.tools.plotting import andrews_curves\n",
    "#andrews_curves(df, 'wheat_type', alpha=0.4)\n",
    "\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "#parallel_coordinates(df, 'wheat_type', alpha=0.4)\n",
    "\n",
    "#Load data\n",
    "#X = pd.read_csv('path/data.csv', index_col='name', names=['','']\n",
    "    # , delimiter='\\t')\n",
    "#pd.read_html('http://url')[0]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#model = RandomForestClassifier(\n",
    "#n_estimators=30,max_depth=10,oob_score=True,random_state=0)\n",
    "#score = model.oob_score_\n",
    "\n",
    "from sklearn import tree\n",
    "#dt = tree.DecisionTreeClassifier()\n",
    "#dt.fit(X_train,y_train)\n",
    "#tree.export_graphviz(dt.tree_, out_file='lab5_tree.dot', \n",
    "    #feature_names=X.columns)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#knn = KNeighborsClassifier(n_neighbors=7,weights='distance|uniform')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "#KMeans(n_clusters = num_clusters)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test \n",
    "#= train_test_split(X,y,test_size=0.3,random_state=7)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#svc = SVC(C=1, kernel='linear')\n",
    "#svc.predict(X_test.loc[999].values.reshape(1,-1))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=4,svd_solver='randomized|full')\n",
    "\n",
    "from sklearn import manifold\n",
    "#iso = manifold.Isomap(n_neighbors=NN, n_components=NC)\n",
    "\n",
    "from sklearn import linear_model\n",
    "#model = linear_model.LinearRegression()\n",
    "\n",
    "from sklearn import preprocessing\n",
    "#preprocessor = preprocessing.Normalizer().fit(X_train) \n",
    "#preprocessor = preprocessing.MaxAbsScaler().fit(X_train)\n",
    "#preprocessor = preprocessing.MinMaxScaler().fit(X_train)  \n",
    "#preprocessor = preprocessing.KernelCenterer().fit(X_train) \n",
    "#preprocessing.RobustScaler().fit_transform(data)\n",
    "\n",
    "#random\n",
    "import random, math\n",
    "from sklearn.utils.validation import check_random_state\n",
    "#rng = check_random_state(7)\n",
    "#random_idx = rng.randint(zero.shape[0])\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "#file I/O\n",
    "import scipy.io.wavfile as wavfile\n",
    "#w = wavfile.read('Datasets/recordings/0_jackson_'+str(i)+'.wav')\n",
    "#wavfile.write('Original Test Clip.wav', sample_rate, test.values)\n",
    "#completed_clip = np.hstack((x_test.reshape(1,-1), y_test_prediction))\n",
    "#wavfile.write('Extrapolated Clip.wav', sample_rate, completed_clip[0])\n",
    "#mat = scipy.io.loadmat('Datasets/face_data.mat')\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "#confusion matrix\n",
    "#df.corr()\n",
    "#plt.imshow(X_test.ix[index,:].reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "#plt.colorbar()\n",
    "#tick_marks = [i for i in range(len(df.columns))]\n",
    "#plt.xticks(tick_marks, df.columns, rotation='vertical')\n",
    "#plt.yticks(tick_marks, df.columns)\n",
    "\n",
    "#check null\n",
    "#X[pd.isnull(X).any(axis=1)]\n",
    "\n",
    "#drop column\n",
    "#X.drop('gender',axis=1,inplace=True)\n",
    "\n",
    "#drop Null/NaN row\n",
    "#X.dropna(axis=0, inplace=True)\n",
    "\n",
    "#drop Null/NaN col\n",
    "#X.dropna(axis=1, inplace=True)\n",
    "\n",
    "#fill null\n",
    "#X.fillna(data.nuclei.mean(), inplace=True)\n",
    "\n",
    "#replace column value\n",
    "#X['col_name'].replace({'from_val':'to_value'}, regex=True, inplace=True)\n",
    "\n",
    "#column encoding\n",
    "#X.edibile = X.edibile.map({'e':1, 'p':0})\n",
    "#y = X['class'].astype(\"category\").cat.codes\n",
    "#X = pd.get_dummies(X)\n",
    "#y = pd.get_dummies(X['class'])\n",
    "\n",
    "#range \n",
    "#c_range = np.arange(0.05, 2, 0.05)\n",
    "\n",
    "#type cast\n",
    "#y_test_prediction = y_test_prediction.astype(dtype=np.int16)\n",
    "#pd.to_datetime(df.Date, errors='coerce')\n",
    "#pd.to_numeric(df.col_name,errors='raise')\n",
    "\n",
    "#loop\n",
    "#for NC in range(4,7):\n",
    "\n",
    "#zip\n",
    "#important_features = sorted(zip(important_features.values(), important_features.keys()), reverse=True)\n",
    "\n",
    "#Series\n",
    "#df['label'] = pd.Series(labels, index=df.index)\n",
    "#scaled = pd.DataFrame(scaled, columns=df.columns)\n",
    "\n",
    "#df.describe()\n",
    "#df.head()\n",
    "#df.info()\n",
    "#df.unique()\n",
    "#df.var()\n",
    "#df.dtypes\n",
    "#df.shape\n",
    "#df.iloc[]\n",
    "#df.loc[]\n",
    "#df[]\n",
    "#df.columns = []\n",
    "#df[df.isnull().sum(axis=1) < 4]\n",
    "#df2 = df.eq([], axis=1)\n",
    "#df3 = df[df2.RK == False]\n",
    "#df4.reset_index()\n",
    "#len(df4.PCT.value_counts())\n",
    "#df4['GP'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
