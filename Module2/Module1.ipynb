{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = r\"C:\\Users\\ADEKUNLE\\Documents\\GitHub\\DAT210x\\Module2\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           col0      col1      col2      col3\n",
      "count  4.000000  4.000000  4.000000  4.000000\n",
      "mean  -0.047068 -0.550656  0.409203 -0.447672\n",
      "std    1.029715  0.701720  0.723956  1.300815\n",
      "min   -1.062870 -1.330682 -0.238536 -1.649853\n",
      "25%   -0.807875 -0.880830 -0.143055 -1.475916\n",
      "50%   -0.142899 -0.617291  0.283070 -0.592780\n",
      "75%    0.617907 -0.287118  0.835328  0.435464\n",
      "max    1.160396  0.362640  1.309208  1.044722\n",
      "2   -1.417937\n",
      "3   -1.649853\n",
      "Name: col3, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#%%file assignment2.py\n",
    "# %load assignment2.py #automatically load the python notebook into ipython notebook\n",
    "# %%writefile [-a] assignment2.py #fill the cells back into the python notebook\n",
    "#%save assignment2.py\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Load up the 'tutorial.csv' dataset\n",
    "\n",
    "# .. your code here ..\n",
    "data = pd.read_csv(\"Datasets/tutorial.csv\")\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "# TODO: Print the results of the .describe() method\n",
    "#\n",
    "# .. your code here ..\n",
    "print(data.describe())\n",
    "\n",
    "\n",
    "# TODO: Figure out which indexing method you need to\n",
    "# use in order to index your dataframe with: [2:4,'col3']\n",
    "# And print the results\n",
    "#\n",
    "# .. your code here ..\n",
    "index3 = data.loc[2:4, 'col3'] #'ix' type slicing too is good\n",
    "print(index3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "cmd": "Other",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "cls": "KernelMagics",
        "colors": "BasicMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "copy": "Other",
        "ddir": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "echo": "Other",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "profile": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "ren": "Other",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %colors  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %matplotlib  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%lsmagic get available magic functions in ipythone notebook to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting assignment3.py\n"
     ]
    }
   ],
   "source": [
    "#%%file assignment3.py #alias for %%writefile assignment3.py, will overwrite the file\n",
    "# %load assignment3.py\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Load up the dataset\n",
    "# Ensuring you set the appropriate header column names\n",
    "#\n",
    "# .. your code here ..\n",
    "servoData = pd.read_csv('Datasets/servo.data', names = ['motor', 'screw', 'pgain', 'vgain', 'class'])\n",
    "print(servoData.head())\n",
    "\n",
    "\n",
    "# TODO: Create a slice that contains all entries\n",
    "# having a vgain equal to 5. Then print the \n",
    "# length of (# of samples in) that slice:\n",
    "#\n",
    "# .. your code here ..\n",
    "vgainLess = servoData[servoData.vgain == 5]\n",
    "print(len(vgainLess))\n",
    "\n",
    "# TODO: Create a slice that contains all entries\n",
    "# having a motor equal to E and screw equal\n",
    "# to E. Then print the length of (# of\n",
    "# samples in) that slice:\n",
    "#\n",
    "# .. your code here ..\n",
    "newSlice =servoData[(servoData.motor == 'E') & (servoData.screw == 'E')] \n",
    "print(len(newSlice))\n",
    "\n",
    "\n",
    "# TODO: Create a slice that contains all entries\n",
    "# having a pgain equal to 4. Use one of the\n",
    "# various methods of finding the mean vgain\n",
    "# value for the samples in that slice. Once\n",
    "# you've found it, print it:\n",
    "#\n",
    "# .. your code here ..\n",
    "lastSlice = servoData[servoData.pgain == 4].vgain.mean() #Tried out chaining the process\n",
    "print(lastSlice) \n",
    "#lastSlice = servoData[servoData.pgain == 4]\n",
    "#print(lastSlice.vgain.mean())\n",
    "\n",
    "\n",
    "# TODO: (Bonus) See what happens when you run\n",
    "# the .dtypes method on your dataframe!\n",
    "print(servoData.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting assignment4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile assignment4.py\n",
    "# %load assignment4.py\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Load up the table, and extract the dataset\n",
    "# out of it. If you're having issues with this, look\n",
    "# carefully at the sample code provided in the reading\n",
    "#\n",
    "# .. your code here ..\n",
    "#using Beafiul soup to get the table and save it as a csv file\n",
    "import csv\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('listing.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    url = \"http://www.espn.com/nhl/statistics/player/_/stat/points/sort/points/year/2015/seasontype/2\"\n",
    "    u = urllib.request.urlopen(url)\n",
    "    try:\n",
    "        html = u.read()\n",
    "    finally:\n",
    "        u.close()\n",
    "    soup=BeautifulSoup(html)\n",
    "    for tr in soup.find_all('tr')[2:]:\n",
    "        tds = tr.find_all('td')\n",
    "        row = [elem.text for elem in tds] #initially there was a 'elem.text.encoding('utf-8') here and was giving me issue\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "listing = pd.read_csv(\"listing.csv\", names = ['RK', 'PLAYER', 'TEAM', 'GP', 'G', 'A', 'PTS', '+/-',\\\n",
    "                                              'PIM', 'PTS/G', 'SOG', 'PCT', 'GWG', 'G', 'A', 'G', 'A'],\\\n",
    "                      encoding = 'ISO-8859-1')\n",
    "#listing.drop('RK', axis = 1, inplace = True)\n",
    "#listing.iloc[:, 1].map(lambda x: x.rstrip(\"'\").lstrip(\"'\")) a very good tool to keep 'rstrip()' and 'lstrip()' on pd.Series\n",
    "listing.head()\n",
    "# TODO: Rename the columns so that they match the\n",
    "# column definitions provided to you on the website\n",
    "#\n",
    "# .. your code here ..\n",
    "\n",
    "\n",
    "# TODO: Get rid of any row that has at least 4 NANs in it\n",
    "#\n",
    "# .. your code here ..\n",
    "\n",
    "listing_notNull = listing.dropna(axis = 0, thresh= 4)\n",
    "print(listing_notNull.head())\n",
    "\n",
    "# TODO: At this point, look through your dataset by printing\n",
    "# it. There probably still are some erroneous rows in there.\n",
    "# What indexing command(s) can you use to select all rows\n",
    "# EXCEPT those rows?\n",
    "#\n",
    "# .. your code here ..\n",
    "\n",
    "\n",
    "#suggestions of more pythonic way to do this part!\n",
    "listing_notDup = listing_notNull[listing_notNull['RK'] != 'RK']\n",
    "print(listing_notDup.head())\n",
    "\n",
    "# TODO: Get rid of the 'RK' column\n",
    "#\n",
    "# .. your code here ..\n",
    "\n",
    "listing_notDup.drop('RK', axis = 1, inplace = True)\n",
    "# TODO: Ensure there are no holes in your index by resetting\n",
    "# it. By the way, don't store the original index\n",
    "#\n",
    "# .. your code here ..\n",
    "listing_notDup = listing_notDup.reset_index(drop = True) #'drop = True' ensures that there is no column name index in the data\n",
    "# TODO: Check the data type of all columns, and ensure those\n",
    "# that should be numeric are numeric\n",
    "\n",
    "#Data is all objects because of the way that the data was read in\n",
    "listing_notDup = listing_notDup.apply(lambda x: pd.to_numeric(x, errors = 'ignore'))\n",
    "print(listing_notDup.dtypes)\n",
    "\n",
    "# TODO: Your dataframe is now ready! Use the appropriate \n",
    "# commands to answer the questions on the course lab page.\n",
    "\n",
    "#How many unique rows exits after the cleaning operation\n",
    "listing_notDup.info()\n",
    "\n",
    "#How many unique values are in PCT\n",
    "print(listing_notDup.PCT.nunique()) #nunique() does the job, another lesson for easy analysis the .columnname type of python coding is\n",
    "#                             good and allows for more expression of possible methods on column series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting assignment5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile assignment5.py\n",
    "# %load assignment5.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#\n",
    "# TODO:\n",
    "# Load up the dataset, setting correct header labels.\n",
    "#\n",
    "# .. your code here ..\n",
    "censusData = pd.read_csv(\"Datasets/census.data\", names= ['education', 'age', 'capitalGain', 'race', 'capitalLoss',\\\n",
    "                                                         'hoursPerWeek', 'sex', 'classification'], na_values = '?')\n",
    "censusData.head()\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# TODO:\n",
    "# Use basic pandas commands to look through the dataset... get a\n",
    "# feel for it before proceeding! Do the data-types of each column\n",
    "# reflect the values you see when you look through the data using\n",
    "# a text editor / spread sheet program? If you see 'object' where\n",
    "# you expect to see 'int32' / 'float64', that is a good indicator\n",
    "# that there is probably a string or missing value in a column.\n",
    "\n",
    "#Do dtypes\n",
    "print(censusData.isnull().values.any(), '\\n', '--------------', '\\n', censusData.dtypes)\n",
    "\n",
    "#This shows that we don't have any null value in the dataset but the data contains some unneccasary values cos capitalGain\n",
    "#    is meant to be an integer\n",
    "# use `your_data_frame['your_column'].unique()` to see the unique\n",
    "# values of each column and identify the rogue values. If these\n",
    "# should be represented as nans, you can convert them using\n",
    "# na_values when loading the dataframe.\n",
    "#\n",
    "# .. your code here ..\n",
    "censusData.education.unique()\n",
    "censusData.age.unique()\n",
    "censusData.capitalGain.unique()\n",
    "censusData.race.unique()\n",
    "censusData.capitalLoss.unique()\n",
    "censusData.hoursPerWeek.unique()\n",
    "censusData.sex.unique()\n",
    "censusData.classification.unique()\n",
    "#\n",
    "# TODO:\n",
    "# Look through your data and identify any potential categorical\n",
    "# features. Ensure you properly encode any ordinal and nominal\n",
    "# types using the methods discussed in the chapter.\n",
    "#\n",
    "# Be careful! Some features can be represented as either categorical\n",
    "# or continuous (numerical). Think to yourself, does it generally\n",
    "# make more sense to have a numeric type or a series of categories\n",
    "# for these somewhat ambigious features?\n",
    "#\n",
    "# .. your code here ..\n",
    "\n",
    "#Code to prepare the ordering of column 'education'\n",
    "education = censusData.education.unique()\n",
    "education.tolist()\n",
    "#To Do:\n",
    "#Reorder the education list\n",
    "orderEdu = [7, 3, 0, 5, 1, 12, 2, 9, 6, 8, 10, 11]\n",
    "neweducation = [education[i] for i in orderEdu]\n",
    "print(neweducation)\n",
    "print(education)\n",
    "\n",
    "#Merge these ordering to education to create a nominal row\n",
    "censusData.education = censusData.education.astype('category', ordered = True, \\\n",
    "                                                  categories = neweducation)\n",
    "\n",
    "#censusData.education = censusData.education.dropna()\n",
    "censusData.capitalGain = censusData.capitalGain.interpolate()\n",
    "censusData.head()\n",
    "print('The data type of column education is:', '%s' % censusData.education.dtype) \n",
    "\n",
    "\n",
    "#check if any value has Nan value\n",
    "print(censusData.isnull().any())\n",
    "censusData.dropna(inplace = True)\n",
    "#Reprint check if Nan value is in data\n",
    "censusData.reset_index(drop = True)\n",
    "#censusData.head()\n",
    "#You can print 'censusData.isnull().any()' to check if there is still null values\n",
    "#censusData.education = censusData.education.astype('category', ordered = True, categories = neweducation)\n",
    "#censusData.education.cat.codes\n",
    "\n",
    "#Apply get_dummies on 'sex', 'race' and 'classification'\n",
    "censusData = pd.get_dummies(censusData, columns= ['race', 'sex', 'classification'])\n",
    "\n",
    "# TODO:\n",
    "# Print out your dataframe\n",
    "#\n",
    "# .. your code here ..\n",
    "print(censusData.head())\n",
    "\n",
    "#I have been told that 'classification' should take ordinal values rather than nominal values(questionable though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Doing this is wrong to do this, because the classification is either '<=50K' or >50k\n",
    "#apply lstrip on classification column to strip off the '<=>' NB. lstrip/rstrip take multipe elements to strip each may be\n",
    "#       unique to different values in the column\n",
    "#censusData['classification'] = censusData.classification.map(lambda x: x.lstrip('<=>').rstrip('K'))\n",
    "#censusData.classification.unique() "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
